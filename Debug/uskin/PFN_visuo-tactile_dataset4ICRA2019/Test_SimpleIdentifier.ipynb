{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3715d39-b998-423b-9c43-16f0d0c0267a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dataset] root=./All_materials/\n",
      "[dataset] num_classes=25 num_samples=250\n",
      "[slice] seq_start=400 seq_end=1200 (len=800)\n",
      "[features] X shape=(250, 96) (should be [N, 96])\n",
      "xva : [14  1  3 22  2 21 23 10 22 10 18 18  6 20 21  3  0  3 11  8 18  9 21 15\n",
      "  2 19 15 24 23 11  2 14  9 13 16  4 13  5  1 14 21 14 20  8  9  8  7  0\n",
      "  3 17 23 19  6 12 11  5 20 14  1 19 18 13  7 15 22 10 20 18  4  5 12 14\n",
      " 16 16 17 22  7  9 22 11 10 13 24  3 12 19 10 18  4  9  1 12 10  7  9  6\n",
      "  0  8 22  2 23 16 15 19 12  0 24  6 24 17  8 23 14 20 13 20  5 23  0  3\n",
      " 16 16  5  1  3 10 15 18 16 12 15 19 14  0 24 16 22 11 17 13  9 17  7  8\n",
      " 13 21 13  1  5  1  2  2  3 11 12 22 24  4 23  6 23 21 15 17  5  7 18  6\n",
      "  7  4  0  9 19  6 20 11 15 20  4  1  2  5 17 17  7  8 21 11  6 10  2 21\n",
      " 19 12  4 24  8  0  4 24]\n",
      "yva head: [16 22 24 23 10  9  8  5 19 17  0  2  3 14  2 10  7 15 13  1 11  5 22 21\n",
      "  4  8 24  4 20 15]\n",
      "[fold 0] acc=100.00%  dummy=4.00%\n",
      "xva : [ 7  6 24 11  3  1 14 11 21 12 23 20  1 22 10 17  5 24  1 10  9  0 22 22\n",
      " 19 24  1  6  0 10  5  2 14 20 13 23 12  0  8 23 17 11 20 21 21  0  7 22\n",
      " 15 10  5 17 12 21 19 23  4 19 16 23 16 17 10 13 23  8 14 15 21  9  1 16\n",
      "  7 16  0 13  6 19 24 20 13  4 17  2  8 16 14  5 18 18  1  2  3 12  5 11\n",
      " 20  3  6  7  7  4 14 18  0 16 19 14 11  7 15 24 13 16 24 18 12 22 23 22\n",
      "  8 18  2  1  6  9 10  9  7  9  6 14 20 19 20  4 13 14 15  4 13  3 21 20\n",
      " 21 10  8  5  3  9 15 17  3 12  7  4 11 12 10  2  8  8 21  5 22  4 22  5\n",
      " 19  6 24  3 18  2 15  9 23 19 11  0 16  4  2 24  9  2 12 18  1  0 13  3\n",
      " 17 17  6 15 11  8 18 15]\n",
      "yva head: [23  4 13 14 13  4 22 20  1  2  0 11  8 14  8 17 22 11 23 10 19  2 18 10\n",
      "  7 24 21 16  7  1]\n",
      "[fold 1] acc=100.00%  dummy=4.00%\n",
      "xva : [ 5 18 22 15  0 21  3 17  4  6 24 21 17  3  1  6 24 12  1  3 18 23 23  0\n",
      " 23  5 14  2 16  4 18 21  0 24 11 11 20 12  4 14 23 17 13 15 13 10 20 17\n",
      "  8 13  7  6 20 15  3 10  7 20 20  3 20 12 19  1 15 22  0 23  5 12 22  9\n",
      " 14 12 10  9 24  2  2 22  5 12  9 18  3 22 22 11 13  9 19 15 19 16 17 24\n",
      "  8  0  5 10  6 17 13  8 22 10 21  6  8  1 23 10  3 20  7 24  2  0 19  9\n",
      "  0  4 16  9 21 19 14  7 13  4  3 16 21 11  6 23  8 21 11 14 18  4  5 16\n",
      " 15 19 18 11  5 17 24 24  8 15 14 13 20  1 10  7 21 16  4  7  1 12  1 18\n",
      "  0 11 19  1  6 10  7  7  2 17 14 12 15  8  6 11  9  2  4  5  9 22 16 16\n",
      " 18  8 23 14  2 19  2 13]\n",
      "yva head: [20 11 13 17 11 22 10 21 12  0  4  4  3 19 22  8  5 16  1  8  2  6 24 15\n",
      "  6  3 17  2  1  5]\n",
      "[fold 2] acc=100.00%  dummy=4.00%\n",
      "xva : [21 18 13 15 20  6 18 11  4 14  9 20  9  2 24  3 12 18  7 14 10 18  1  2\n",
      " 23 16 21 20 20  6 15  3 11 21 18 12  5 11  6 17  9  9 23 10 13  5 14  2\n",
      "  1 12 16 14 10 17  6  7 16 24  1 22  8  6 22  3 24  0 13  8  7 11 15 23\n",
      " 21  5 18 11 22  8  7 14  4 10  0 21  9 22 24 14  8 23  9 19 13 15 13  4\n",
      "  2  8  7 11  4  5  6  5 23 17 14 11 19 15  3  9 13 24  4 16 12  0 17  2\n",
      "  7 15 14  3 20  7 24 19 12  1 17 22 21 10 15 17 10  4 22 22 18  2 13 12\n",
      "  3  0 20  0 21  2 20 23  8 16 23  0  0 11 19 20 23  1 21 17  5 10 19  5\n",
      "  3  3 10 12  6 22 19 24  9  8  0 15  4  4  7 17 16 18  1 19 12 16  1  2\n",
      "  1 19  8  6 13 24  5 16]\n",
      "yva head: [ 8  3 10  1 18  5  6 12  0 14 17 22 13  6  5 20 17 21 15  0 24 24 18 23\n",
      " 16 15 11  8 13 11]\n",
      "[fold 3] acc=100.00%  dummy=4.00%\n",
      "xva : [13  4 13 23  1 10  4 22  9 12  6 24  0 11 13 11 21  4 19 11 24  6 11 20\n",
      " 20 12 21 22 23 12  2 17 22  7 10  0 18 10  9 16 16 24 14 21 19  8 16 18\n",
      " 16 19  2 21 12  6 15 16 13  3  8 19 17  7 17 15 12 21  7  6  4 11  9 23\n",
      "  3  3  2 23  2 15 18  4  5 24 18 18  4  4  0  9 17  8 18 17  3 17 10  1\n",
      "  6 10  3 22 14 23  3  1  8  7 11 24  3  8  1 24  6 20  5 13  5 22 19 15\n",
      " 12 13 18 14 17 13  0 20  5  0 14 16  3  5 21  7  8  7 14 10  1  5 14 21\n",
      "  6  8 14 21 15 16 20 19 15 11  2 12  5 22 22 20  1 23 19 13 17 23 10  9\n",
      " 12 16 15 22 15 14  9 24  8  4  0  7  2  1 11 10  9 19  0 23  0  5 20  6\n",
      "  2  1 20  7 24  2 18  9]\n",
      "yva head: [17 23  2 22  5  8  6  0 10 10  0 14 20 18 20 22  7 17  2 12  5  3 11 11\n",
      " 24 16  1 13  9  6]\n",
      "[fold 4] acc=100.00%  dummy=4.00%\n",
      "------------------------------------------------------------\n",
      "[CV] mean acc = 100.00%  std = 0.00%\n",
      "[CV] dummy    = 4.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sota/miniforge3/envs/rl-book/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/sota/miniforge3/envs/rl-book/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/sota/miniforge3/envs/rl-book/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/sota/miniforge3/envs/rl-book/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/sota/miniforge3/envs/rl-book/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def collect_paths_and_labels(dataset_root: str):\n",
    "    \"\"\"\n",
    "    dataset_root/\n",
    "      classA/*.npy\n",
    "      classB/*.npy\n",
    "      ...\n",
    "    を想定。class名のソート順にラベル index を振る。\n",
    "    \"\"\"\n",
    "    root = Path(dataset_root)\n",
    "    class_names = sorted([d.name for d in root.iterdir() if d.is_dir()])\n",
    "    if not class_names:\n",
    "        raise RuntimeError(f\"No class directories under: {root}\")\n",
    "\n",
    "    class_to_idx = {c: i for i, c in enumerate(class_names)}\n",
    "    paths = []\n",
    "    labels = []\n",
    "    for c in class_names:\n",
    "        for p in sorted((root / c).glob(\"*.npy\")):\n",
    "            paths.append(str(p))\n",
    "            labels.append(class_to_idx[c])\n",
    "\n",
    "    if not paths:\n",
    "        raise RuntimeError(f\"No .npy found under: {root}\")\n",
    "\n",
    "    return paths, np.array(labels, dtype=np.int64), class_names\n",
    "\n",
    "\n",
    "def extract_features_mean_std(npy_path: str, seq_start: int, seq_end: int):\n",
    "    \"\"\"\n",
    "    超単純特徴：時間平均(48) + 時間std(48) の 96次元\n",
    "    入力 .npy は (T, n_taxels, 3) を想定\n",
    "    \"\"\"\n",
    "    arr = np.load(npy_path)  # (T, n_taxels, 3)\n",
    "    if arr.ndim != 3 or arr.shape[-1] != 3:\n",
    "        raise ValueError(f\"Invalid shape {arr.shape} in {npy_path}\")\n",
    "\n",
    "    if seq_end > arr.shape[0]:\n",
    "        raise ValueError(f\"seq_end({seq_end}) > T({arr.shape[0]}) in {npy_path}\")\n",
    "\n",
    "    x = arr[seq_start:seq_end]  # (seq_len, n_taxels, 3)\n",
    "    x = x.reshape(x.shape[0], -1).astype(np.float32)  # (seq_len, 48)\n",
    "\n",
    "    mu = x.mean(axis=0)  # (48,)\n",
    "    sd = x.std(axis=0)   # (48,)\n",
    "    feat = np.concatenate([mu, sd], axis=0)  # (96,)\n",
    "    return feat\n",
    "\n",
    "\n",
    "def build_feature_matrix(paths, seq_start: int, seq_end: int):\n",
    "    X = np.stack([extract_features_mean_std(p, seq_start, seq_end) for p in paths], axis=0)\n",
    "    return X\n",
    "\n",
    "\n",
    "def run_linear_baseline_cv(dataset_root: str, seq_start: int, seq_end: int,\n",
    "                           n_splits: int = 5, seed: int = 0):\n",
    "    paths, y, class_names = collect_paths_and_labels(dataset_root)\n",
    "    print(f\"[dataset] root={dataset_root}\")\n",
    "    print(f\"[dataset] num_classes={len(class_names)} num_samples={len(paths)}\")\n",
    "    print(f\"[slice] seq_start={seq_start} seq_end={seq_end} (len={seq_end-seq_start})\")\n",
    "\n",
    "    # ★ 重要：paths と y を「ペアのまま」先にシャッフル（順序依存を消す）\n",
    "    rng = np.random.RandomState(seed)\n",
    "    perm = rng.permutation(len(paths))\n",
    "    paths = [paths[i] for i in perm]\n",
    "    y = y[perm]\n",
    "\n",
    "    X = build_feature_matrix(paths, seq_start, seq_end)\n",
    "    print(f\"[features] X shape={X.shape} (should be [N, 96])\")\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"lr\", LogisticRegression(\n",
    "            max_iter=5000,\n",
    "            multi_class=\"multinomial\",\n",
    "            solver=\"lbfgs\",\n",
    "            n_jobs=None\n",
    "        )),\n",
    "    ])\n",
    "\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "    accs = []\n",
    "    dummy_accs = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y)):\n",
    "        # ★ 見た目＆学習の順序もシャッフル（分割集合自体は同じ）\n",
    "        rng_fold = np.random.RandomState(seed + 1000 + fold)\n",
    "        tr_idx = tr_idx[rng_fold.permutation(len(tr_idx))]\n",
    "        va_idx = va_idx[rng_fold.permutation(len(va_idx))]\n",
    "\n",
    "        Xtr, Xva = X[tr_idx], X[va_idx]\n",
    "        ytr, yva = y[tr_idx], y[va_idx]\n",
    "\n",
    "        clf.fit(Xtr, ytr)\n",
    "        pred = clf.predict(Xva)\n",
    "        acc = accuracy_score(yva, pred)\n",
    "        accs.append(acc)\n",
    "\n",
    "        dummy.fit(Xtr, ytr)\n",
    "        dpred = dummy.predict(Xva)\n",
    "        dacc = accuracy_score(yva, dpred)\n",
    "        dummy_accs.append(dacc)\n",
    "\n",
    "        # ここで print すると、yva が「連続ラベル」になりにくい\n",
    "        print(\"xva :\", ytr)\n",
    "        print(\"yva head:\", yva[:30])\n",
    "        print(f\"[fold {fold}] acc={acc*100:.2f}%  dummy={dacc*100:.2f}%\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"[CV] mean acc = {np.mean(accs)*100:.2f}%  std = {np.std(accs)*100:.2f}%\")\n",
    "    print(f\"[CV] dummy    = {np.mean(dummy_accs)*100:.2f}%\")\n",
    "    return accs\n",
    "\n",
    "\n",
    "\n",
    "# ==== 実行例 ====\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_root = \"./All_materials/\"  # あなたのデータ\n",
    "    seq_start = 400\n",
    "    seq_end = 1200\n",
    "    run_linear_baseline_cv(dataset_root, seq_start, seq_end, n_splits=5, seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19666ea4-b9ef-4b88-bfa8-f2528930f7ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m y \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mpermutation(\u001b[43my\u001b[49m)\n\u001b[1;32m      4\u001b[0m accs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (tr_idx, va_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(skf\u001b[38;5;241m.\u001b[39msplit(X, y_shuf)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "y = rng.permutation(y)\n",
    "\n",
    "accs = []\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y_shuf)):\n",
    "    clf.fit(X[tr_idx], y_shuf[tr_idx])\n",
    "    pred = clf.predict(X[va_idx])\n",
    "    acc = accuracy_score(y_shuf[va_idx], pred)\n",
    "    accs.append(acc)\n",
    "    print(f\"[shuf fold {fold}] acc={acc*100:.2f}%\")\n",
    "print(\"mean:\", np.mean(accs)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c883071-4f7a-4093-9492-af2c01356693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
