{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f08f23c-75fe-4089-ba30-2eb374fe444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 files in ./Lyon_decimation_128 を読み込んでいます...\n",
      "データ読み込み完了．\n",
      "train_input : (16957, 77)\n",
      "train_output: (16957, 10)\n",
      "train_length: (250,) sum= 16957\n",
      "train_label : (250,)\n",
      "test_input  : (17150, 77)\n",
      "test_output : (17150, 10)\n",
      "test_length : (250,) sum= 17150\n",
      "test_label  : (250,)\n"
     ]
    }
   ],
   "source": [
    "# lyon_loader_torch.py\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.io import loadmat\n",
    "\n",
    "\n",
    "import os, glob, re\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Optional\n",
    "from scipy.io import loadmat\n",
    "\n",
    "def _parse_filename_strict_compat(path: str):\n",
    "    utterance = int(path[-8])\n",
    "    digit = int(path[-5])\n",
    "    return utterance, digit\n",
    "\n",
    "def _parse_filename_regex(path: str):\n",
    "    base = os.path.basename(path)\n",
    "    m = re.search(r\"s(\\d+)_u(\\d+)_d(\\d)\\.mat$\", base)\n",
    "    if m is None:\n",
    "        raise ValueError(f\"Unexpected filename format: {base}\")\n",
    "    utterance = int(m.group(2))\n",
    "    digit = int(m.group(3))\n",
    "    return utterance, digit\n",
    "\n",
    "def read_lyon_decimation_128_torch(\n",
    "    dir_name: str,\n",
    "    utterance_train_list=(1, 2, 3, 4, 5),\n",
    "    n_channel: int = 77,\n",
    "    n_label: int = 10,\n",
    "    strict_compat_filename: bool = True,\n",
    "    sort_files: bool = True,\n",
    "    device: Optional[torch.device] = None,   # Py3.9互換\n",
    "    dtype: torch.dtype = torch.float32,\n",
    "):\n",
    "    data_files = glob.glob(os.path.join(dir_name, \"*.mat\"))\n",
    "    if len(data_files) == 0:\n",
    "        raise FileNotFoundError(f\"No .mat files found in: {dir_name}\")\n",
    "\n",
    "    if sort_files:\n",
    "        data_files = sorted(data_files)\n",
    "\n",
    "    parser = _parse_filename_strict_compat if strict_compat_filename else _parse_filename_regex\n",
    "    train_set = set(utterance_train_list)\n",
    "\n",
    "    train_x_list, train_y_list, train_len_list, train_lab_list = [], [], [], []\n",
    "    test_x_list,  test_y_list,  test_len_list,  test_lab_list  = [], [], [], []\n",
    "\n",
    "    print(f\"{len(data_files)} files in {dir_name} を読み込んでいます...\")\n",
    "\n",
    "    for each_file in data_files:\n",
    "        data = loadmat(each_file)\n",
    "        if \"spec\" not in data:\n",
    "            raise KeyError(f\"'spec' not found in mat file: {each_file}\")\n",
    "\n",
    "        spec = data[\"spec\"]  # [77, n_tau]\n",
    "        if spec.shape[0] != n_channel:\n",
    "            raise ValueError(f\"spec.shape[0] != {n_channel}: {each_file}, shape={spec.shape}\")\n",
    "\n",
    "        utterance, digit = parser(each_file)\n",
    "        n_tau = spec.shape[1]\n",
    "\n",
    "        x = torch.from_numpy(np.ascontiguousarray(spec.T)).to(dtype=dtype)  # [n_tau,77]\n",
    "        y = -torch.ones((n_tau, n_label), dtype=dtype)\n",
    "        y[:, digit] = 1.0\n",
    "\n",
    "        if utterance in train_set:\n",
    "            train_x_list.append(x); train_y_list.append(y)\n",
    "            train_len_list.append(n_tau); train_lab_list.append(digit)\n",
    "        else:\n",
    "            test_x_list.append(x); test_y_list.append(y)\n",
    "            test_len_list.append(n_tau); test_lab_list.append(digit)\n",
    "\n",
    "    train_input  = torch.cat(train_x_list, dim=0) if train_x_list else torch.empty((0, n_channel), dtype=dtype)\n",
    "    train_output = torch.cat(train_y_list, dim=0) if train_y_list else torch.empty((0, n_label), dtype=dtype)\n",
    "    test_input   = torch.cat(test_x_list,  dim=0) if test_x_list  else torch.empty((0, n_channel), dtype=dtype)\n",
    "    test_output  = torch.cat(test_y_list,  dim=0) if test_y_list  else torch.empty((0, n_label), dtype=dtype)\n",
    "\n",
    "    train_length = torch.tensor(train_len_list, dtype=torch.long)\n",
    "    train_label  = torch.tensor(train_lab_list, dtype=torch.long)\n",
    "    test_length  = torch.tensor(test_len_list, dtype=torch.long)\n",
    "    test_label   = torch.tensor(test_lab_list, dtype=torch.long)\n",
    "\n",
    "    if train_input.shape[0] != int(train_length.sum().item()):\n",
    "        raise RuntimeError(\"train_input rows != sum(train_length)\")\n",
    "    if test_input.shape[0] != int(test_length.sum().item()):\n",
    "        raise RuntimeError(\"test_input rows != sum(test_length)\")\n",
    "\n",
    "    if device is not None:\n",
    "        train_input  = train_input.to(device)\n",
    "        train_output = train_output.to(device)\n",
    "        test_input   = test_input.to(device)\n",
    "        test_output  = test_output.to(device)\n",
    "        train_length = train_length.to(device)\n",
    "        train_label  = train_label.to(device)\n",
    "        test_length  = test_length.to(device)\n",
    "        test_label   = test_label.to(device)\n",
    "\n",
    "    return (train_input, train_output, train_length, train_label,\n",
    "            test_input, test_output, test_length, test_label)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    train_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "    (train_input, train_output, train_length, train_label,\n",
    "     test_input,  test_output,  test_length,  test_label) = read_lyon_decimation_128_torch(\n",
    "        dir_name=\"./Lyon_decimation_128\",\n",
    "        utterance_train_list=train_list,\n",
    "        strict_compat_filename=True,   # 参考コード互換（デフォルト）\n",
    "        sort_files=True,\n",
    "        device=None,                   # まずはCPUで一致確認推奨\n",
    "    )\n",
    "\n",
    "    print(\"データ読み込み完了．\")\n",
    "    print(\"train_input :\", tuple(train_input.shape))\n",
    "    print(\"train_output:\", tuple(train_output.shape))\n",
    "    print(\"train_length:\", tuple(train_length.shape), \"sum=\", int(train_length.sum().item()))\n",
    "    print(\"train_label :\", tuple(train_label.shape))\n",
    "\n",
    "    print(\"test_input  :\", tuple(test_input.shape))\n",
    "    print(\"test_output :\", tuple(test_output.shape))\n",
    "    print(\"test_length :\", tuple(test_length.shape), \"sum=\", int(test_length.sum().item()))\n",
    "    print(\"test_label  :\", tuple(test_label.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beaa3bba-7f7b-4e22-8111-e3b7a4008851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 files in ./Lyon_decimation_128 を読み込んでいます...\n",
      "訓練誤差： WER = 0.0120\n",
      "検証誤差： WER = 0.0760\n"
     ]
    }
   ],
   "source": [
    "# check_lyon_esn_ridge_with_helpers.py\n",
    "# (1)逐次更新→(2)状態全結合→(3)既存のリッジ回帰更新→(4)多数決WER\n",
    "# 参考コードと同じ「全発話を連結」前提。混同行列は見ない。\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os, glob, re\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Optional\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# --- あなたの環境に合わせて import を調整してください ---\n",
    "\n",
    "# あなたの ESN 実装（ReadOut クラスを含む）\n",
    "from esn_model import ESN, ReadOut\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ヘルパー\n",
    "from rc_timeseries_helpers import (\n",
    "    infer_device_from_model,\n",
    "    extract_states_time_major,\n",
    "    extract_logits_time_major,\n",
    "    apply_time_selection,\n",
    "    prepare_time_distributed_targets,\n",
    ")\n",
    "\n",
    "def read_lyon_decimation_128_torch(\n",
    "    dir_name: str,\n",
    "    utterance_train_list=(1, 2, 3, 4, 5),\n",
    "    n_channel: int = 77,\n",
    "    n_label: int = 10,\n",
    "    strict_compat_filename: bool = True,\n",
    "    sort_files: bool = True,\n",
    "    device: Optional[torch.device] = None,   # Py3.9互換\n",
    "    dtype: torch.dtype = torch.float32,\n",
    "):\n",
    "    data_files = glob.glob(os.path.join(dir_name, \"*.mat\"))\n",
    "    if len(data_files) == 0:\n",
    "        raise FileNotFoundError(f\"No .mat files found in: {dir_name}\")\n",
    "\n",
    "    if sort_files:\n",
    "        data_files = sorted(data_files)\n",
    "\n",
    "    parser = _parse_filename_strict_compat if strict_compat_filename else _parse_filename_regex\n",
    "    train_set = set(utterance_train_list)\n",
    "\n",
    "    train_x_list, train_y_list, train_len_list, train_lab_list = [], [], [], []\n",
    "    test_x_list,  test_y_list,  test_len_list,  test_lab_list  = [], [], [], []\n",
    "\n",
    "    print(f\"{len(data_files)} files in {dir_name} を読み込んでいます...\")\n",
    "\n",
    "    for each_file in data_files:\n",
    "        data = loadmat(each_file)\n",
    "        if \"spec\" not in data:\n",
    "            raise KeyError(f\"'spec' not found in mat file: {each_file}\")\n",
    "\n",
    "        spec = data[\"spec\"]  # [77, n_tau]\n",
    "        if spec.shape[0] != n_channel:\n",
    "            raise ValueError(f\"spec.shape[0] != {n_channel}: {each_file}, shape={spec.shape}\")\n",
    "\n",
    "        utterance, digit = parser(each_file)\n",
    "        n_tau = spec.shape[1]\n",
    "\n",
    "        x = torch.from_numpy(np.ascontiguousarray(spec.T)).to(dtype=dtype)  # [n_tau,77]\n",
    "        y = -torch.ones((n_tau, n_label), dtype=dtype)\n",
    "        y[:, digit] = 1.0\n",
    "\n",
    "        if utterance in train_set:\n",
    "            train_x_list.append(x); train_y_list.append(y)\n",
    "            train_len_list.append(n_tau); train_lab_list.append(digit)\n",
    "        else:\n",
    "            test_x_list.append(x); test_y_list.append(y)\n",
    "            test_len_list.append(n_tau); test_lab_list.append(digit)\n",
    "\n",
    "    train_input  = torch.cat(train_x_list, dim=0) if train_x_list else torch.empty((0, n_channel), dtype=dtype)\n",
    "    train_output = torch.cat(train_y_list, dim=0) if train_y_list else torch.empty((0, n_label), dtype=dtype)\n",
    "    test_input   = torch.cat(test_x_list,  dim=0) if test_x_list  else torch.empty((0, n_channel), dtype=dtype)\n",
    "    test_output  = torch.cat(test_y_list,  dim=0) if test_y_list  else torch.empty((0, n_label), dtype=dtype)\n",
    "\n",
    "    train_length = torch.tensor(train_len_list, dtype=torch.long)\n",
    "    train_label  = torch.tensor(train_lab_list, dtype=torch.long)\n",
    "    test_length  = torch.tensor(test_len_list, dtype=torch.long)\n",
    "    test_label   = torch.tensor(test_lab_list, dtype=torch.long)\n",
    "\n",
    "    if train_input.shape[0] != int(train_length.sum().item()):\n",
    "        raise RuntimeError(\"train_input rows != sum(train_length)\")\n",
    "    if test_input.shape[0] != int(test_length.sum().item()):\n",
    "        raise RuntimeError(\"test_input rows != sum(test_length)\")\n",
    "\n",
    "    if device is not None:\n",
    "        train_input  = train_input.to(device)\n",
    "        train_output = train_output.to(device)\n",
    "        test_input   = test_input.to(device)\n",
    "        test_output  = test_output.to(device)\n",
    "        train_length = train_length.to(device)\n",
    "        train_label  = train_label.to(device)\n",
    "        test_length  = test_length.to(device)\n",
    "        test_label   = test_label.to(device)\n",
    "\n",
    "    return (train_input, train_output, train_length, train_label,\n",
    "            test_input, test_output, test_length, test_label)\n",
    "\n",
    "# -------------------------\n",
    "# small helpers (length-vote)\n",
    "# -------------------------\n",
    "@torch.no_grad()\n",
    "def predict_labels_by_lengths_majority_vote(logits_BTC, lengths):\n",
    "    \"\"\"\n",
    "    logits_BTC: [B=1, T, C]  （連結系列）\n",
    "    lengths:    [num_utterances]  （各発話の長さ）\n",
    "    return pred: [num_utterances] long\n",
    "    \"\"\"\n",
    "    assert logits_BTC.dim() == 3 and logits_BTC.size(0) == 1\n",
    "    logits_TC = logits_BTC[0]  # [T,C]\n",
    "    C = logits_TC.size(1)\n",
    "\n",
    "    preds = []\n",
    "    start = 0\n",
    "    for L in lengths.tolist():\n",
    "        seg = logits_TC[start:start + L]          # [L,C]\n",
    "        idx_t = seg.argmax(dim=-1)                # [L]\n",
    "        hist = torch.bincount(idx_t, minlength=C) # [C]\n",
    "        preds.append(int(hist.argmax().item()))\n",
    "        start += L\n",
    "\n",
    "    if start != logits_TC.size(0):\n",
    "        raise RuntimeError(f\"sum(lengths)={start} != T={logits_TC.size(0)} (lengths/concat mismatch)\")\n",
    "    return torch.tensor(preds, dtype=torch.long, device=logits_BTC.device)\n",
    "\n",
    "def wer_from_preds(pred, true):\n",
    "    return (pred != true).float().mean().item()\n",
    "\n",
    "def to_BcTD(x_TD):\n",
    "    \"\"\"[T,D] -> [B=1,ch=1,T,D]\"\"\"\n",
    "    return x_TD.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# -------------------------\n",
    "# main check pipeline\n",
    "# -------------------------\n",
    "@torch.no_grad()\n",
    "def run_lyon_check(\n",
    "    model,\n",
    "    train_input_TD, train_output_TC, train_length, train_label,\n",
    "    test_input_TD,  test_output_TC,  test_length,  test_label,\n",
    "    alpha=0.0,\n",
    "    washout_steps=0,\n",
    "    time_stride=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    train_input_TD : [T_train, D]\n",
    "    train_output_TC: [T_train, C]  (Lyon: -1/+1)\n",
    "    train_length   : [num_train_utts]\n",
    "    train_label    : [num_train_utts] (0..9)\n",
    "    同様に test_* も。\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # ---- (1) 逐次更新 -> (2) 状態全結合（ただし shape は [B,T,H] を保つ） ----\n",
    "    xtr_BcTD = to_BcTD(train_input_TD).to(device)     # [1,1,T,D]\n",
    "    states_tr_BcTH = model.ESN(xtr_BcTD)              # [1,1,T,H]\n",
    "    states_tr_BTH = extract_states_time_major(states_tr_BcTH)  # [1,T,H]\n",
    "\n",
    "    # logits（回帰前の形状確認用：重み更新後に再計算するので必須ではない）\n",
    "    # logits_tr_BTC_pre = extract_logits_time_major(model.ReadOut(states_tr_BcTH))\n",
    "\n",
    "    # ---- ターゲットを [B,T,C] で用意（ヘルパー利用）----\n",
    "    ytr_BTC_in = train_output_TC.unsqueeze(0).to(device)  # [1,T,C]\n",
    "    B, T, C = ytr_BTC_in.shape\n",
    "\n",
    "    # washout/stride を使うなら states と targets に同じ selection をかける\n",
    "    states_tr_BTH = apply_time_selection(states_tr_BTH, washout_steps, time_stride)\n",
    "    ytr_BTC_in    = apply_time_selection(ytr_BTC_in,    washout_steps, time_stride)\n",
    "\n",
    "    B2, T2, H = states_tr_BTH.shape\n",
    "    assert (B2, T2) == ytr_BTC_in.shape[:2]\n",
    "\n",
    "    targets_tr_BTC, _ = prepare_time_distributed_targets(\n",
    "        labels=ytr_BTC_in,\n",
    "        batch_size=B2,\n",
    "        time_steps=T2,\n",
    "        num_classes=C,\n",
    "        device=device\n",
    "    )  # [1,T2,C]（ここでは入力と同一のはず）\n",
    "\n",
    "    # ---- (3) 既存の ESN リッジ回帰関数で ReadOut 重み更新 ----\n",
    "    # 既存実装は X を [H,N]、Y を [C,N] として渡す前提（N=B*T）\n",
    "    X_HN = states_tr_BTH.reshape(B2 * T2, H).T.contiguous()     # [H,N]\n",
    "    Y_CN = targets_tr_BTC.reshape(B2 * T2, C).T.contiguous()    # [C,N]\n",
    "\n",
    "    # 既存関数で更新（alpha=0 なら「リッジ無し」だが solve が不安定なら小さく正則化）\n",
    "    ReadOut.ridge_regression_update(outputs=X_HN, targets=Y_CN, model=model, alpha=alpha)\n",
    "\n",
    "    # ---- 更新後に logits を計算（形状を保って [B,T,C] に）----\n",
    "    logits_tr_BTC = extract_logits_time_major(model.ReadOut(states_tr_BcTH))  # [1,T,C]\n",
    "    logits_tr_BTC = apply_time_selection(logits_tr_BTC, washout_steps, time_stride)\n",
    "\n",
    "    # 注意：washout/stride を使う場合、発話ごとの lengths も対応させる必要がある（ここでは未対応）\n",
    "    if washout_steps != 0 or time_stride != 1:\n",
    "        raise NotImplementedError(\"washout/stride を使う場合は発話ごとの length 変換も必要です。まずは 0/1 で一致確認してください。\")\n",
    "\n",
    "    pred_train = predict_labels_by_lengths_majority_vote(logits_tr_BTC, train_length.to(device))\n",
    "    train_WER = wer_from_preds(pred_train, train_label.to(device))\n",
    "\n",
    "    # ---- test 側（重みは train のまま）----\n",
    "    xte_BcTD = to_BcTD(test_input_TD).to(device)\n",
    "    states_te_BcTH = model.ESN(xte_BcTD)\n",
    "    logits_te_BTC = extract_logits_time_major(model.ReadOut(states_te_BcTH))  # [1,T,C]\n",
    "\n",
    "    pred_test = predict_labels_by_lengths_majority_vote(logits_te_BTC, test_length.to(device))\n",
    "    test_WER = wer_from_preds(pred_test, test_label.to(device))\n",
    "\n",
    "    return train_WER, test_WER\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # --- Lyon 読み込み（参考コードと同様 train_list=[1..5]） ---\n",
    "    train_list = [1, 2, 3, 4, 5]\n",
    "    (train_input, train_output, train_length, train_label,\n",
    "     test_input,  test_output,  test_length,  test_label) = read_lyon_decimation_128_torch(\n",
    "        dir_name=\"./Lyon_decimation_128\",\n",
    "        utterance_train_list=train_list,\n",
    "        strict_compat_filename=True,\n",
    "        sort_files=False,   # 参考コードが glob 順固定でないので、まず False を推奨\n",
    "        device=None,\n",
    "    )\n",
    "\n",
    "    # --- ESN 構築（Lyon向けの例：あなたの params 名に合わせて調整） ---\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model_params = {\n",
    "        \"reservoir_size\": 100,\n",
    "        \"reservoir_weights_scale\": 1.0,\n",
    "        \"input_size\": 77,\n",
    "        \"channel_size\": 1,\n",
    "        \"input_weights_scale\": 1.0e4,     # 参考: input_scale\n",
    "        \"spectral_radius\": 0.9,           # 参考: rho\n",
    "        \"reservoir_density\": 0.05,        # 参考: density\n",
    "        \"leak_rate\": 1.0,                 # 参考コードに寄せるなら 1.0 推奨\n",
    "        \"ReadOut_output_size\": 10,\n",
    "        \"Batch_Training\": True,\n",
    "    }\n",
    "    dataset_params = {\"sequence_length\": 1, \"slicing_size\": 1}\n",
    "    training_params = {}\n",
    "\n",
    "    model = ESN(model_params, training_params, dataset_params).to(device)\n",
    "\n",
    "    # --- 実行（まずは washout=0, stride=1 で一致確認） ---\n",
    "    train_WER, test_WER = run_lyon_check(\n",
    "        model=model,\n",
    "        train_input_TD=train_input, train_output_TC=train_output,\n",
    "        train_length=train_length, train_label=train_label,\n",
    "        test_input_TD=test_input, test_output_TC=test_output,\n",
    "        test_length=test_length, test_label=test_label,\n",
    "        alpha=0.0,           # solve が不安定なら 1e-6 〜 1e-2 を試す\n",
    "        washout_steps=0,\n",
    "        time_stride=1,\n",
    "    )\n",
    "\n",
    "    print(f\"訓練誤差： WER = {train_WER:.4f}\")\n",
    "    print(f\"検証誤差： WER = {test_WER:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64418d8e-668d-4e4f-9d31-2e7343670e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
