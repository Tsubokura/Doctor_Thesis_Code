{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6a0c05-f70f-44bd-b300-6587a012f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import random \n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, random_split, Subset\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e08e914-0074-45d8-84ef-de89ffa76e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnekodaisuki169\u001b[0m (\u001b[33mdoctor_thesis_material\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/sota/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# WandBの設定\n",
    "WANDB_API_KEY = \"2d996a98ef8dddefa91d675f85b5efd96fb911ae\"  # あなたのWandB APIキーをここに入力してください\n",
    "\n",
    "wandb.login(key = WANDB_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32eeab35-0455-463a-92a8-1db2c7c3fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_FILENAME_RE = re.compile(r\"s(\\d+)_u(\\d+)_d(\\d+)\\.mat$\", re.IGNORECASE)\n",
    "\n",
    "def _parse_lyon_filename(path: str):\n",
    "    base = os.path.basename(path)\n",
    "    m = _FILENAME_RE.match(base)\n",
    "    if m is None:\n",
    "        raise ValueError(f\"Unexpected filename format: {base} (expected s*_u*_d*.mat)\")\n",
    "    speaker = int(m.group(1))\n",
    "    utterance = int(m.group(2))\n",
    "    digit = int(m.group(3))\n",
    "    return speaker, utterance, digit\n",
    "\n",
    "class LyonDecimation128Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Lyon_decimation_128 (TI 46 digit) dataset for PyTorch.\n",
    "\n",
    "    Returns per file:\n",
    "      x_time:  (T, 77) float32\n",
    "      y_time:  (T, 10) float32 with -1/+1 coding (digit col = +1, others = -1)\n",
    "      y_seq:   (10,)  float32 one-hot (0/1)  ※デバッグ/他実装の互換用\n",
    "      length:  int (T)\n",
    "      label:   int (digit)\n",
    "      meta:    dict (speaker, utterance, filename)\n",
    "    \"\"\"\n",
    "    def __init__(self, dir_name: str, utterance_train_list, split: str = \"train\",\n",
    "                 n_channel: int = 77, n_label: int = 10,\n",
    "                 target_pm1: bool = True,\n",
    "                 time_slice=None,  # (start, end) or None\n",
    "                 debug_print_first: bool = False):\n",
    "        super().__init__()\n",
    "        self.dir_name = dir_name\n",
    "        self.dir = Path(dir_name)\n",
    "        self.utterance_train_list = set(utterance_train_list)\n",
    "        self.split = split\n",
    "        self.n_channel = n_channel\n",
    "        self.n_label = n_label\n",
    "        self.target_pm1 = target_pm1\n",
    "        self.time_slice = time_slice\n",
    "        self.debug_print_first = debug_print_first\n",
    "        self.files = sorted(self.dir.glob(\"*.mat\"))\n",
    "        self.pattern = re.compile(r\"s(\\d+)_u(\\d+)_d(\\d+)\\.mat$\")\n",
    "\n",
    "        self.speaker_ids = []\n",
    "        self.utterance_ids = []\n",
    "        self.digit_ids = []\n",
    "\n",
    "        valid_files = []\n",
    "        for p in self.files:\n",
    "            m = self.pattern.search(p.name)\n",
    "            if m is None:\n",
    "                continue\n",
    "            s = int(m.group(1))\n",
    "            u = int(m.group(2))\n",
    "            d = int(m.group(3))\n",
    "            valid_files.append(p)\n",
    "            self.speaker_ids.append(s)\n",
    "            self.utterance_ids.append(u)\n",
    "            self.digit_ids.append(d)\n",
    "\n",
    "        paths = sorted(glob.glob(os.path.join(dir_name, \"*.mat\")))\n",
    "        if not paths:\n",
    "            raise RuntimeError(f\"No .mat files found in: {dir_name}\")\n",
    "\n",
    "        items = []\n",
    "        for p in paths:\n",
    "            speaker, utterance, digit = _parse_lyon_filename(p)\n",
    "            is_train = utterance in self.utterance_train_list\n",
    "            if (split == \"train\" and is_train) or (split == \"test\" and (not is_train)):\n",
    "                items.append((p, speaker, utterance, digit))\n",
    "\n",
    "        if not items:\n",
    "            raise RuntimeError(f\"No files matched split='{split}'. Check utterance_train_list.\")\n",
    "\n",
    "        self.items = items\n",
    "\n",
    "        # 長さ統計（デバッグ用）\n",
    "        lens = []\n",
    "        for (p, *_rest) in self.items[:20]:  # 最初の20個だけ軽く見る\n",
    "            spec = loadmat(p)[\"spec\"]  # expected (77, T)\n",
    "            lens.append(int(spec.shape[1]))\n",
    "        self._len_preview = lens\n",
    "\n",
    "        if self.debug_print_first:\n",
    "            print(f\"[LyonDataset] split={split} n_files={len(self.items)} preview_T={self._len_preview}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        path, speaker, utterance, digit = self.items[idx]\n",
    "        mat = loadmat(path)\n",
    "        spec = mat[\"spec\"]  # expected shape (77, T)\n",
    "\n",
    "        if spec.shape[0] != self.n_channel:\n",
    "            raise ValueError(f\"spec.shape[0] != {self.n_channel}: got {spec.shape} in {path}\")\n",
    "\n",
    "        # (77, T) -> (T, 77)\n",
    "        x = spec.T.astype(np.float32)\n",
    "\n",
    "        # optional time slicing\n",
    "        if self.time_slice is not None:\n",
    "            s, e = self.time_slice\n",
    "            x = x[s:e]\n",
    "\n",
    "        T = x.shape[0]\n",
    "\n",
    "        # y_time: (T, 10)\n",
    "        if self.target_pm1:\n",
    "            y = -np.ones((T, self.n_label), dtype=np.float32)\n",
    "            y[:, digit] = 1.0\n",
    "        else:\n",
    "            # 0/1 encoding\n",
    "            y = np.zeros((T, self.n_label), dtype=np.float32)\n",
    "            y[:, digit] = 1.0\n",
    "\n",
    "        # y_seq: (10,) (0/1)\n",
    "        y_seq = np.zeros((self.n_label,), dtype=np.float32)\n",
    "        y_seq[digit] = 1.0\n",
    "\n",
    "        x_t = torch.from_numpy(x)              # (T, 77)\n",
    "        y_t = torch.from_numpy(y)              # (T, 10)\n",
    "        y_seq_t = torch.from_numpy(y_seq)      # (10,)\n",
    "        length = T\n",
    "        label = int(digit)\n",
    "\n",
    "        meta = {\"speaker\": speaker, \"utterance\": utterance, \"filename\": os.path.basename(path)}\n",
    "\n",
    "        return x_t, y_t, y_seq_t, length, label, meta\n",
    "\n",
    "\n",
    "\n",
    "# class LyonDecimation128Dataset(Dataset):\n",
    "#     def __init__(self, dir_name):\n",
    "#         self.dir = Path(dir_name)\n",
    "#         self.files = sorted(self.dir.glob(\"*.mat\"))\n",
    "#         if not self.files:\n",
    "#             raise RuntimeError(f\"No .mat files in {dir_name}\")\n",
    "\n",
    "#         self.pattern = re.compile(r\"s(\\d+)_u(\\d+)_d(\\d+)\\.mat$\")\n",
    "\n",
    "#         self.speaker_ids = []\n",
    "#         self.utterance_ids = []\n",
    "#         self.digit_ids = []\n",
    "\n",
    "#         valid_files = []\n",
    "#         for p in self.files:\n",
    "#             m = self.pattern.search(p.name)\n",
    "#             if m is None:\n",
    "#                 continue\n",
    "#             s = int(m.group(1))\n",
    "#             u = int(m.group(2))\n",
    "#             d = int(m.group(3))\n",
    "#             valid_files.append(p)\n",
    "#             self.speaker_ids.append(s)\n",
    "#             self.utterance_ids.append(u)\n",
    "#             self.digit_ids.append(d)\n",
    "\n",
    "#         self.files = valid_files\n",
    "#         if not self.files:\n",
    "#             raise RuntimeError(\"No valid Lyon files matched pattern s*_u*_d*.mat\")\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.files)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         p = self.files[idx]\n",
    "#         data = loadmat(p)\n",
    "#         spec = data[\"spec\"]                  # (77, T)\n",
    "#         x = spec.T.astype(np.float32)        # (T,77)\n",
    "#         T = x.shape[0]\n",
    "\n",
    "#         x = torch.from_numpy(x).unsqueeze(0) # (1,T,77)\n",
    "\n",
    "#         digit = self.digit_ids[idx]\n",
    "#         y = -torch.ones(10, dtype=torch.float32)\n",
    "#         y[digit] = 1.0\n",
    "\n",
    "#         # ここで utterance なども返しておくとデバッグが楽\n",
    "#         labels = {\n",
    "#             \"y\": y,  # (10,)\n",
    "#             \"length\": torch.tensor(T, dtype=torch.long),\n",
    "#             \"label_idx\": torch.tensor(digit, dtype=torch.long),\n",
    "#             \"utterance\": torch.tensor(self.utterance_ids[idx], dtype=torch.long),\n",
    "#             \"speaker\": torch.tensor(self.speaker_ids[idx], dtype=torch.long),\n",
    "#             \"file\": p.name,\n",
    "#         }\n",
    "#         return x, labels\n",
    "\n",
    "\n",
    "def collate_pad_lyon(batch):\n",
    "    # batch: list of (x_time(T,77), y_time(T,10), y_seq(10), length, label, meta)\n",
    "    xs, ys, yseqs, lengths, labels, metas = zip(*batch)\n",
    "\n",
    "    B = len(xs)\n",
    "    Tmax = max(lengths)\n",
    "    C_in = xs[0].shape[1]   # 77\n",
    "    C_out = ys[0].shape[1]  # 10\n",
    "\n",
    "    x_pad = torch.zeros((B, 1, Tmax, C_in), dtype=torch.float32)     # (B,1,T,77)\n",
    "    y_pad = torch.zeros((B, Tmax, C_out), dtype=torch.float32)       # (B,T,10)\n",
    "    mask  = torch.zeros((B, Tmax), dtype=torch.bool)\n",
    "\n",
    "    # y の padding 値は -1 で埋める（pm1 前提なら重要）\n",
    "    # ※ target_pm1=False のときは 0 埋めが自然。必要ならここを条件分岐してもOK。\n",
    "    y_pad[:] = -1.0\n",
    "\n",
    "    for i in range(B):\n",
    "        T = lengths[i]\n",
    "        x_pad[i, 0, :T, :] = xs[i]\n",
    "        y_pad[i, :T, :] = ys[i]\n",
    "        mask[i, :T] = True\n",
    "\n",
    "    y_seq = torch.stack(yseqs, dim=0)            # (B,10)\n",
    "    lengths_t = torch.tensor(lengths, dtype=torch.long)  # (B,)\n",
    "    labels_t  = torch.tensor(labels, dtype=torch.long)   # (B,)\n",
    "\n",
    "    return x_pad, y_pad, y_seq, lengths_t, labels_t, mask, metas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90b49d4-4536-4ae3-b55e-80758b66f6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LyonDataset] split=train n_files=250 preview_T=[49, 42, 49, 59, 57, 64, 71, 59, 50, 62, 49, 38, 44, 51, 57, 65, 73, 69, 53, 66]\n",
      "x_pad   : torch.Size([8, 1, 95, 77])\n",
      "y_pad   : torch.Size([8, 95, 10])\n",
      "y_seq   : torch.Size([8, 10])\n",
      "lengths : tensor([70, 95, 62, 83, 59, 79, 79, 48])\n",
      "labels  : tensor([0, 9, 1, 7, 4, 6, 8, 2])\n",
      "mask    : torch.Size([8, 95]) 575\n",
      "meta[0] : {'speaker': 6, 'utterance': 2, 'filename': 's6_u2_d0.mat'}\n"
     ]
    }
   ],
   "source": [
    "train_list = [1,2,3,4,5]\n",
    "train_ds = LyonDecimation128Dataset(\"./Lyon_decimation_128\", train_list, split=\"train\",\n",
    "                                    target_pm1=True, debug_print_first=True)\n",
    "test_ds  = LyonDecimation128Dataset(\"./Lyon_decimation_128\", train_list, split=\"test\",\n",
    "                                    target_pm1=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, collate_fn=collate_pad_lyon)\n",
    "test_loader  = DataLoader(test_ds, batch_size=8, shuffle=False, collate_fn=collate_pad_lyon)\n",
    "\n",
    "# 1バッチだけ shape 確認\n",
    "x_pad, y_pad, y_seq, lengths, labels, mask, metas = next(iter(train_loader))\n",
    "print(\"x_pad   :\", x_pad.shape)    # (B,1,Tmax,77)\n",
    "print(\"y_pad   :\", y_pad.shape)    # (B,Tmax,10)\n",
    "print(\"y_seq   :\", y_seq.shape)    # (B,10)\n",
    "print(\"lengths :\", lengths)        # (B,)\n",
    "print(\"labels  :\", labels)         # (B,)\n",
    "print(\"mask    :\", mask.shape, mask.sum().item())\n",
    "print(\"meta[0] :\", metas[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0882e39-81e6-4e0b-b43e-dc69034082df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EchoStateNetwork(nn.Module):\n",
    "    def __init__(self, model_params, dataset_params):\n",
    "        super(EchoStateNetwork, self).__init__()\n",
    "        \n",
    "        self.reservoir_size = int(model_params[\"reservoir_size\"])\n",
    "        self.reservoir_weights_scale = float(model_params[\"reservoir_weights_scale\"])\n",
    "        \n",
    "        self.input_size = int(model_params[\"input_size\"])\n",
    "        self.channel_size = int(model_params[\"channel_size\"])\n",
    "        self.input_weights_scale = float(model_params[\"input_weights_scale\"])\n",
    "        self.spectral_radius = float(model_params[\"spectral_radius\"])\n",
    "        self.density = float(model_params[\"reservoir_density\"])\n",
    "        self.leak_rate = float(model_params[\"leak_rate\"])\n",
    "        \n",
    "        self.sequence_length = int(int(dataset_params[\"sequence_length\"]) / int(dataset_params[\"slicing_size\"]))\n",
    "        # self.sequence_length = int(dataset_params[\"seq_end\"]) - int(dataset_params[\"seq_start\"])\n",
    "\n",
    "        # リザバー結合行列 (ランダムに初期化)\n",
    "        self.register_parameter(\"reservoir_weights\", torch.nn.Parameter(torch.empty((self.reservoir_size, self.reservoir_size)).uniform_(-self.reservoir_weights_scale, self.reservoir_weights_scale).to(device), requires_grad=False))\n",
    "        \n",
    "        # リザバー入力行列 (ランダムに初期化)\n",
    "        self.register_parameter(\"input_weights\", torch.nn.Parameter(torch.empty((self.reservoir_size, self.input_size * self.channel_size)).uniform_(-self.input_weights_scale, self.input_weights_scale).to(device), requires_grad=False))\n",
    "        \n",
    "        \n",
    "\n",
    "        #リザバー結合のスパース処理\n",
    "        self.reservoir_weights_mask = torch.empty((self.reservoir_size, self.reservoir_size)).uniform_(0, 1)\n",
    "        self.reservoir_weights_mask = torch.where(self.reservoir_weights_mask < self.density, torch.tensor(1), torch.tensor(0)).to(device)\n",
    "        self.reservoir_weights *= self.reservoir_weights_mask\n",
    "        \n",
    "        #スペクトル半径の処理\n",
    "        _, singular_values, _ = torch.svd(self.reservoir_weights)\n",
    "        rho_reservoir_weights = torch.max(singular_values).item()\n",
    "        self.reservoir_weights *= self.spectral_radius / rho_reservoir_weights\n",
    "        \n",
    "       #最終時刻における，リザバー状態ベクトル\n",
    "        self.last_reservoir_state_matrix = torch.zeros(self.channel_size, self.reservoir_size).to(device)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.size(0)\n",
    "        sequence_length = x.size(2)\n",
    "        # x_seq = x.view(batch_size, self.channel_size, self.input_size, sequence_length).to(device)\n",
    "\n",
    "        # if self.last_reservoir_state_matrix is None or self.last_reservoir_state_matrix.size(0) != batch_size:\n",
    "        #     self.last_reservoir_state_matrix = torch.zeros(\n",
    "        #         batch_size, self.channel_size, self.reservoir_size, device=device\n",
    "        #     )\n",
    "        \n",
    "        # 各シーケンスのバッチに対してリザバー状態を初期化\n",
    "        self.reservoir_state_matrix = torch.zeros(batch_size, self.channel_size,  sequence_length, self.reservoir_size).to(device)\n",
    "\n",
    "        self.last_reservoir_state_matrix = torch.zeros(\n",
    "                batch_size, self.channel_size, self.reservoir_size, device=device\n",
    "            )\n",
    "        \n",
    "        for t in range(sequence_length):\n",
    "            input_at_t = torch.matmul(x[:, :, t, :].view(batch_size, -1), self.input_weights.t())\n",
    "            input_at_t = input_at_t.unsqueeze(1)\n",
    "\n",
    "            if t == 0:\n",
    "                state_update = torch.matmul(self.last_reservoir_state_matrix, self.reservoir_weights)\n",
    "            else:\n",
    "                # print(\"11111\")\n",
    "                state_update = torch.matmul(self.reservoir_state_matrix[:, :, t-1, :], self.reservoir_weights)\n",
    "                # print(f\"state_update.shape {state_update.shape}\")\n",
    "            self.reservoir_state_matrix[:, :, t, :] = self.leak_rate * torch.tanh(input_at_t + state_update) + \\\n",
    "                                                    (1 - self.leak_rate) * self.reservoir_state_matrix[:, :, t-1, :]\n",
    "\n",
    "        \n",
    "\n",
    "        self.last_reservoir_state_matrix = self.reservoir_state_matrix[:, :, -1, :]\n",
    "        return self.reservoir_state_matrix\n",
    "\n",
    "    def reset_hidden_state(self):\n",
    "        self.last_reservoir_state_matrix = torch.zeros(self.channel_size, self.reservoir_size, device=device)\n",
    "        # pass\n",
    "        # print(\"内部状態がリセットされました\")\n",
    "    \n",
    "#リードアウト層\n",
    "class ReadOut(nn.Module):\n",
    "    def __init__(self, model_params, dataset_params):\n",
    "        super(ReadOut, self).__init__()\n",
    "        # self.reservoir_state_matrix_size = int(model_params[\"reservoir_size\"]) + int(model_params[\"input_size\"]) + 1\n",
    "        self.reservoir_state_matrix_size = int(model_params[\"reservoir_size\"])\n",
    "        self.output_size = int(model_params[\"ReadOut_output_size\"])\n",
    "        self.batch_training = model_params[\"Batch_Training\"]\n",
    "        self.channel_size = int(model_params[\"channel_size\"])\n",
    "        \n",
    "        self.sequence_length = int(int(dataset_params[\"sequence_length\"]) / int(dataset_params[\"slicing_size\"]))\n",
    "        # self.sequence_length = int(dataset_params[\"seq_end\"]) - int(dataset_params[\"seq_start\"])\n",
    "        \n",
    "        self.readout_dense = nn.Linear(self.reservoir_state_matrix_size, self.output_size, bias=False)\n",
    "        \n",
    "        #線形回帰におけるバッチ学習を行うならば，リードアウト層を最急降下法による学習対象にしない\n",
    "        if self.batch_training == True:\n",
    "            self.readout_dense.weight.requires_grad = False\n",
    "        else:\n",
    "            None\n",
    "            \n",
    "        nn.init.xavier_uniform_(self.readout_dense.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, channel_size, input_size, sequence_length]\n",
    "        # batch_size, channel_size, input_size, sequence_length = x.size()\n",
    "        \n",
    "        # Reshape x to apply the dense layer to each time step and channel independently\n",
    "        # New shape: [batch_size * channel_size * sequence_length, input_size]\n",
    "        # x_reshaped = x.permute(0, 1, 3, 2).contiguous().view(-1, input_size)\n",
    "        \n",
    "        # Apply the dense layer\n",
    "        # Output shape: [batch_size * channel_size * sequence_length, output_size]\n",
    "        # print(f\"readout x shape{x.shape}\")\n",
    "        output = self.readout_dense(x)\n",
    "        \n",
    "        # Reshape the output back to the original form\n",
    "        # Output shape: [batch_size, channel_size, output_size, sequence_length]\n",
    "        # output = output.view(batch_size, channel_size, sequence_length, -1).permute(0, 1, 3, 2).contiguous()\n",
    "        return output\n",
    "    \n",
    "    # リッジ回帰によるリードアウトの導出\n",
    "    @staticmethod\n",
    "    def ridge_regression(X, Y, alpha):\n",
    "        # データ行列 X の形状を取得\n",
    "        n, p = X.shape\n",
    "\n",
    "        # 正則化項の行列を作成\n",
    "        ridge_matrix = (alpha * torch.eye(n)).float().to(device)\n",
    "        X = X.float()\n",
    "        Y = Y.float()\n",
    "\n",
    "        # リッジ回帰の係数を計算\n",
    "        coefficients = torch.linalg.solve(torch.matmul(X, X.T) + ridge_matrix, torch.matmul(X, Y.T)).T\n",
    "\n",
    "        return coefficients\n",
    "\n",
    "    @staticmethod\n",
    "    def ridge_regression_update(outputs, targets, model, alpha=0):\n",
    "        with torch.no_grad():\n",
    "            # リッジ回帰を用いて重みを求める\n",
    "            # モデルのパラメータを更新\n",
    "            new_weights = ReadOut.ridge_regression(outputs.squeeze(), targets.squeeze(), alpha)\n",
    "\n",
    "            # モデルのパラメータを更新\n",
    "            model.ReadOut.readout_dense.weight.copy_(new_weights)\n",
    "        \n",
    "        return None\n",
    "    #それぞれのモデルパラメータ候補を辞書に格納する\n",
    "    @staticmethod\n",
    "    def model_params_candinate(model_params):\n",
    "        model_params_combinations = list(itertools.product(*model_params.values()))\n",
    "        param_dicts = [dict(zip(model_params.keys(), combination)) for combination in model_params_combinations]\n",
    "        \n",
    "        return param_dicts\n",
    "\n",
    "    #モデル構造を辞書型に格納\n",
    "    @staticmethod\n",
    "    def model_sturcture_dict(model):\n",
    "        layers_dict = {}\n",
    "        for name, module in model.named_modules():\n",
    "            layers_dict[name] = {\n",
    "                'type': type(module).__name__,\n",
    "                'parameters': {p: getattr(module, p) for p in module.__dict__ if not p.startswith('_')}\n",
    "            }\n",
    "        \n",
    "        #モデル名と初期の引数は削除\n",
    "        del(layers_dict[''])\n",
    "        \n",
    "        return layers_dict\n",
    "\n",
    "class ESN(nn.Module):\n",
    "    def __init__(self, model_params, training_params, dataset_params):\n",
    "        super(ESN, self).__init__()\n",
    "        self.ESN = EchoStateNetwork(model_params, dataset_params)\n",
    "        self.ReadOut = ReadOut(model_params, dataset_params)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.Reservoir_State_Matrix = self.ESN(x)\n",
    "        # print(f\"resever state matrix {self.Reservoir_State_Matrix.shape}\")\n",
    "        self.ReadOut_Reservoir = self.ReadOut(self.Reservoir_State_Matrix)\n",
    "        # print(\"重み:\", self.ReadOut.readout_dense.weight)\n",
    "        # print(self.ReadOut_Reservoir)\n",
    "\n",
    "        #channle_size次元はいらないので，減らす\n",
    "        self.ReadOut_Reservoir = self.ReadOut_Reservoir.squeeze(1)\n",
    "        # print(f\"output matrix {self.ReadOut_Reservoir.shape}\")\n",
    "\n",
    "        return self.ReadOut_Reservoir\n",
    "\n",
    "    def reset_hidden_state(self):\n",
    "        self.ESN.reset_hidden_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92edc84a-9505-4e3d-993d-ca7aaa973e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# K分割交差検証とデータローダーの生成\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "def create_cross_validation_dataloaders(dataset, dataset_params, traing_params, train_list):\n",
    "    \"\"\"\n",
    "    Lyon原コード準拠：\n",
    "      train_list に含まれる utterance(u) → train\n",
    "      それ以外 → val\n",
    "    戻り値は (train_loader, val_loader) を1組だけ入れたリスト\n",
    "    \"\"\"\n",
    "    batch_size = int(dataset_params[\"batch_size\"])\n",
    "\n",
    "    train_idx = [i for i, u in enumerate(dataset.utterance_ids) if u in train_list]\n",
    "    val_idx   = [i for i, u in enumerate(dataset.utterance_ids) if u not in train_list]\n",
    "\n",
    "    if len(train_idx) == 0 or len(val_idx) == 0:\n",
    "        raise RuntimeError(f\"Split error: train={len(train_idx)}, val={len(val_idx)}. train_list={train_list}\")\n",
    "\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset   = Subset(dataset, val_idx)\n",
    "\n",
    "    # あなたの方針どおり “フルバッチ” にしたい場合は len(train_subset) を使う\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=len(train_subset),      # ←元コード踏襲（フルバッチ）\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_pad_lyon\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=len(val_subset),        # ←元コード踏襲（フルバッチ）\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_pad_lyon\n",
    "    )\n",
    "\n",
    "    # 互換性のため list で返す（fold=0 だけ回る）\n",
    "    return [(train_loader, val_loader)]\n",
    "\n",
    "def prepare_datasets(dataset_params, traing_params, data_dir, train_list):\n",
    "    dataset = LyonDecimation128Dataset(data_dir, train_list)\n",
    "\n",
    "    cross_val_loaders = create_cross_validation_dataloaders(\n",
    "        dataset, dataset_params, traing_params, train_list\n",
    "    )\n",
    "\n",
    "    # Lyon原コードは明確な test を別に持たないので、ここでは None にしておくのが安全\n",
    "    test_loader = None\n",
    "    return cross_val_loaders, test_loader\n",
    "\n",
    "def debug_split(dataset, train_list):\n",
    "    from collections import Counter\n",
    "    train_u = [u for u in dataset.utterance_ids if u in train_list]\n",
    "    val_u   = [u for u in dataset.utterance_ids if u not in train_list]\n",
    "    print(\"[DEBUG] total:\", len(dataset))\n",
    "    print(\"[DEBUG] train:\", len(train_u), \"val:\", len(val_u))\n",
    "    print(\"[DEBUG] train utterance counts:\", Counter(train_u))\n",
    "    print(\"[DEBUG] val utterance counts  :\", Counter(val_u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ff2e9dd-d502-41bb-94d8-684426f2eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_batch_for_lyon(batch):\n",
    "    \"\"\"\n",
    "    train_loader が返す batch の形式が複数あり得るので吸収する\n",
    "\n",
    "    return:\n",
    "      inputs: Tensor (B,1,T,F)\n",
    "      labels: Tensor (B,C)  ※one-hot or ±1\n",
    "      lengths: Tensor (B,) or None\n",
    "      mask: Tensor (B,T) bool or None\n",
    "      label_idx: Tensor (B,) long or None\n",
    "      extra: 何かあれば（ファイル名など）\n",
    "    \"\"\"\n",
    "    if isinstance(batch, (list, tuple)):\n",
    "        if len(batch) == 2:\n",
    "            inputs, labels = batch\n",
    "            return inputs, labels, None, None, None, None\n",
    "\n",
    "        # よくある Lyon 可変長形式\n",
    "        if len(batch) >= 5:\n",
    "            inputs = batch[0]\n",
    "            labels = batch[1]\n",
    "            lengths = batch[2]\n",
    "            mask = batch[3]\n",
    "            label_idx = batch[4]\n",
    "            extra = batch[5:] if len(batch) > 5 else None\n",
    "            return inputs, labels, lengths, mask, label_idx, extra\n",
    "\n",
    "    raise ValueError(f\"Unexpected batch format: type={type(batch)}, batch={batch}\")\n",
    "\n",
    "\n",
    "def _debug_check_view_mapping(outputs, outputs_flatten, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    outputs: (B,T,C)\n",
    "    outputs_flatten: (C, B*T) を想定\n",
    "    期待対応: outputs_flatten[:, b*T + t] == outputs[b,t,:]\n",
    "    \"\"\"\n",
    "    if outputs.dim() != 3 or outputs_flatten.dim() != 2:\n",
    "        print(prefix, \"skip mapping check (dim mismatch)\")\n",
    "        return\n",
    "\n",
    "    B, T, C = outputs.shape\n",
    "    if outputs_flatten.shape[0] != C:\n",
    "        print(prefix, f\"skip mapping check: outputs_flatten[0]={outputs_flatten.shape[0]} != C={C}\")\n",
    "        return\n",
    "\n",
    "    # いくつかサンプル点を比較\n",
    "    check_points = [(0,0), (0,1), (0, min(5, T-1))]\n",
    "    if B >= 2:\n",
    "        check_points += [(1,0), (1, min(5, T-1))]\n",
    "\n",
    "    for (b,t) in check_points:\n",
    "        j = b*T + t\n",
    "        if j >= outputs_flatten.shape[1]:\n",
    "            continue\n",
    "        diff = (outputs[b, t, :] - outputs_flatten[:, j]).abs().max().item()\n",
    "        print(prefix, f\"view-map check (b={b},t={t},j={j}) max|diff|={diff:.6g}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5892294-5337-4f93-9584-310490ac3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, dataset_params, model_params, traing_params):\n",
    "    model.train()\n",
    "    num_epochs = int(traing_params[\"num_epochs\"])\n",
    "    reservoir_size = int(model_params[\"reservoir_size\"])\n",
    "    batch_training = model_params[\"Batch_Training\"]\n",
    "    Regularization_L2 = model_params[\"Regularization_L2\"]\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for it, batch in enumerate(train_loader):\n",
    "            inputs, labels, lengths, mask, label_idx, extra = unpack_batch_for_lyon(batch)\n",
    "\n",
    "            inputs = inputs.float().to(device)\n",
    "\n",
    "            # labels が dict のケースにも対応（あなたがどっちで返しててもOKにする）\n",
    "            if isinstance(labels, dict):\n",
    "                y = labels[\"y\"].to(device)               # (B,C)\n",
    "                if mask is None and \"mask\" in labels:    # loader側で dict に入れてる場合\n",
    "                    mask = labels[\"mask\"]\n",
    "                if lengths is None and \"lengths\" in labels:\n",
    "                    lengths = labels[\"lengths\"]\n",
    "                if label_idx is None and \"label_idx\" in labels:\n",
    "                    label_idx = labels[\"label_idx\"]\n",
    "            else:\n",
    "                y = labels.to(device)                    # (B,C)\n",
    "\n",
    "            if mask is not None:\n",
    "                mask = mask.to(device)                   # (B,T) bool\n",
    "            if lengths is not None:\n",
    "                lengths = lengths.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs_ESN = model.ESN(inputs)\n",
    "            outputs = model.ReadOut(outputs_ESN)\n",
    "            outputs = outputs.squeeze()                  # (B,T,C) を期待\n",
    "\n",
    "            if outputs.dim() != 3:\n",
    "                raise ValueError(f\"[train] outputs must be (B,T,C), got {outputs.shape}\")\n",
    "\n",
    "            B, T, C = outputs.shape\n",
    "\n",
    "            # ===== デバッグ表示（最初の1バッチだけ）=====\n",
    "            if epoch == 0 and it == 0:\n",
    "                print(\"===== [DEBUG train first batch] =====\")\n",
    "                print(\"batch type/len:\", type(batch), len(batch) if isinstance(batch,(list,tuple)) else \"N/A\")\n",
    "                print(\"inputs      :\", tuple(inputs.shape), \"contig=\", inputs.is_contiguous())\n",
    "                print(\"y           :\", tuple(y.shape))\n",
    "                print(\"outputs_ESN :\", tuple(outputs_ESN.shape), \"contig=\", outputs_ESN.is_contiguous())\n",
    "                print(\"outputs     :\", tuple(outputs.shape), \"contig=\", outputs.is_contiguous())\n",
    "                if mask is not None:\n",
    "                    print(\"mask        :\", tuple(mask.shape), \"valid_frames=\", int(mask.sum().item()))\n",
    "                if lengths is not None:\n",
    "                    print(\"lengths[:8] :\", lengths[:min(8,B)].tolist())\n",
    "                print(\"=====================================\")\n",
    "\n",
    "            # ===== 可変長対応：padding を無効化（viewの前に掛ける）=====\n",
    "            if mask is not None:\n",
    "                mask_f = mask.float()\n",
    "                outputs = outputs * mask_f.unsqueeze(-1)\n",
    "\n",
    "                # outputs_ESN にもマスク（形状に応じて）\n",
    "                if outputs_ESN.dim() == 4:         # (B,1,T,H)\n",
    "                    outputs_ESN = outputs_ESN * mask_f.unsqueeze(1).unsqueeze(-1)\n",
    "                elif outputs_ESN.dim() == 3:       # (B,T,H)\n",
    "                    outputs_ESN = outputs_ESN * mask_f.unsqueeze(-1)\n",
    "\n",
    "            # ---- flattenの整合性（ここはあなたの元コードを維持）----\n",
    "            outputs_ESN_flatten = outputs_ESN.view(reservoir_size, -1)\n",
    "            outputs_flatten     = outputs.view(C, -1)\n",
    "\n",
    "            labels_rep = y.unsqueeze(1).repeat(1, T, 1)   # (B,T,C)\n",
    "\n",
    "            if mask is not None:\n",
    "                labels_rep = labels_rep * mask_f.unsqueeze(-1)\n",
    "\n",
    "            labels_flatten = labels_rep.view(C, -1)\n",
    "\n",
    "            if epoch == 0 and it == 0:\n",
    "                print(\"[DEBUG] outputs_flatten:\", tuple(outputs_flatten.shape))\n",
    "                print(\"[DEBUG] labels_flatten :\", tuple(labels_flatten.shape))\n",
    "                if lengths is not None:\n",
    "                    Ti = int(lengths[0].item())\n",
    "                    tail_energy = outputs[0, Ti:, :].abs().sum().item()\n",
    "                    print(f\"[DEBUG] tail_energy(sample0 after Ti={Ti}) = {tail_energy:.6g} (should be ~0 if mask ok)\")\n",
    "\n",
    "            loss = criterion(outputs_flatten, labels_flatten)\n",
    "\n",
    "            if batch_training == True:\n",
    "                model.ReadOut.ridge_regression_update(outputs_ESN_flatten, labels_flatten, model, Regularization_L2)\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "        wandb.log({\"loss\": epoch_loss})\n",
    "\n",
    "    print(\"Training complete\")\n",
    "\n",
    "def validate_model(model, val_loader, dataset_params, model_params):\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for it, batch in enumerate(val_loader):\n",
    "            inputs, labels, lengths, mask, label_idx, extra = unpack_batch_for_lyon(batch)\n",
    "\n",
    "            inputs = inputs.float().to(device)\n",
    "\n",
    "            if isinstance(labels, dict):\n",
    "                y = labels[\"y\"].to(device)\n",
    "                if mask is None and \"mask\" in labels:\n",
    "                    mask = labels[\"mask\"]\n",
    "                if lengths is None and \"lengths\" in labels:\n",
    "                    lengths = labels[\"lengths\"]\n",
    "            else:\n",
    "                y = labels.to(device)\n",
    "\n",
    "            if mask is not None:\n",
    "                mask = mask.to(device)\n",
    "            if lengths is not None:\n",
    "                lengths = lengths.to(device)\n",
    "\n",
    "            outputs_ESN = model.ESN(inputs)\n",
    "            outputs = model.ReadOut(outputs_ESN).squeeze(1)  # ←あなたの元コード維持\n",
    "\n",
    "            if outputs.dim() != 3:\n",
    "                raise ValueError(f\"[val] outputs must be (B,T,C), got {outputs.shape}\")\n",
    "\n",
    "            B, T, C = outputs.shape\n",
    "\n",
    "            if it == 0:\n",
    "                print(\"===== [DEBUG val first batch] =====\")\n",
    "                print(\"inputs      :\", tuple(inputs.shape))\n",
    "                print(\"y           :\", tuple(y.shape))\n",
    "                print(\"outputs_ESN :\", tuple(outputs_ESN.shape))\n",
    "                print(\"outputs     :\", tuple(outputs.shape))\n",
    "                if mask is not None:\n",
    "                    print(\"mask        :\", tuple(mask.shape), \"valid_frames=\", int(mask.sum().item()))\n",
    "                if lengths is not None:\n",
    "                    print(\"lengths[:8] :\", lengths[:min(8,B)].tolist())\n",
    "                print(\"===================================\")\n",
    "\n",
    "            # padding無効化（viewの前）\n",
    "            if mask is not None:\n",
    "                mask_f = mask.float()\n",
    "                outputs = outputs * mask_f.unsqueeze(-1)\n",
    "\n",
    "            outputs_flatten = outputs.view(C, -1)\n",
    "            labels_rep = y.unsqueeze(1).repeat(1, T, 1)\n",
    "            if mask is not None:\n",
    "                labels_rep = labels_rep * mask_f.unsqueeze(-1)\n",
    "            labels_flatten = labels_rep.view(C, -1)\n",
    "\n",
    "            loss = criterion(outputs_flatten, labels_flatten)  # ←元コード同様 global criterion を使う\n",
    "            val_running_loss += loss.item() * B\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "\n",
    "    # Lyon(可変長)のときは sequence_length 固定 split が破綻するので、\n",
    "    # まずは loss のみで確認するのが安全です（精度は後で“発話単位投票”に差し替え推奨）\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    wandb.log({\"val_loss\": val_loss})\n",
    "\n",
    "\n",
    "    \n",
    "def test_model(model, val_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.float().to(device)\n",
    "            labels = labels.squeeze().to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "#             _, label_preds = torch.max(labels, 1)\n",
    "            label_preds = labels\n",
    "\n",
    "            val_running_loss += loss.item() * inputs.size(0)\n",
    "            print(loss.item())\n",
    "            val_running_corrects += torch.sum(preds == label_preds)\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader.dataset)\n",
    "    val_accuracy = val_running_corrects.double() / len(val_loader.dataset)\n",
    "    \n",
    "    print(f'Test Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n",
    "    wandb.log({\"test_accuracy\": val_accuracy, \"test_loss\": val_loss})\n",
    "\n",
    "def compute_accuracy(model_output, target, n_taus):\n",
    "    # モデルの出力と教師ラベルを各データに分割\n",
    "    split_model_output = torch.split(model_output.squeeze(), n_taus, dim=-1)\n",
    "    split_target = torch.split(target.squeeze(), n_taus, dim=-1)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for pred, true_label in zip(split_model_output, split_target):\n",
    "        # 最も確率が高いラベルを予測ラベルとして取得\n",
    "        # print(pred.shape)\n",
    "        # print(pred)\n",
    "        # print(true_label.shape)\n",
    "        # print(true_label)\n",
    "        count_ones = (true_label == 1).sum().item()\n",
    "        # print(count_ones)\n",
    "        histgram_predict = torch.bincount(torch.max(pred, 0)[1])\n",
    "        _, predicted = torch.max(histgram_predict, 0)\n",
    "    \n",
    "        histgram_true_label_idx = torch.bincount(torch.max(true_label, 0)[1])\n",
    "        _, true_label_idx = torch.max(histgram_true_label_idx, 0)\n",
    "\n",
    "        # 正解数をカウント\n",
    "        correct += (predicted == true_label_idx).sum().item()\n",
    "        total += 1\n",
    "\n",
    "    # 精度を算出\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "def model_params_candinate(model_params):\n",
    "    model_params_combinations = list(itertools.product(*model_params.values()))\n",
    "    param_dicts = [dict(zip(model_params.keys(), combination)) for combination in model_params_combinations]\n",
    "    return param_dicts\n",
    "\n",
    "# モデル構造を辞書型に格納\n",
    "def model_sturcture_dict(model):\n",
    "    layers_dict = {}\n",
    "    for name, module in model.named_modules():\n",
    "        layers_dict[name] = {\n",
    "            'type': type(module).__name__,\n",
    "            'parameters': {p: getattr(module, p) for p in module.__dict__ if not p.startswith('_')}\n",
    "        }\n",
    "    # モデル名と初期の引数は削除\n",
    "    del(layers_dict[''])\n",
    "    return layers_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d775fe13-6dbc-47b8-a21b-4e1cb5d48db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.23.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/sota/Doctor_Thesis_Code/Debug/uskin/PFN_visuo-tactile_dataset4ICRA2019/wandb/run-20251216_092252-rtll5f0n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/doctor_thesis_material/Lyon_test_ESN/runs/rtll5f0n' target=\"_blank\">electric-meadow-7</a></strong> to <a href='https://wandb.ai/doctor_thesis_material/Lyon_test_ESN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/doctor_thesis_material/Lyon_test_ESN' target=\"_blank\">https://wandb.ai/doctor_thesis_material/Lyon_test_ESN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/doctor_thesis_material/Lyon_test_ESN/runs/rtll5f0n' target=\"_blank\">https://wandb.ai/doctor_thesis_material/Lyon_test_ESN/runs/rtll5f0n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFOLD \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meach_model_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m validate_model(model, val_loader,dataset_params, each_model_params)\n\u001b[1;32m     47\u001b[0m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(each_model_params, training_params, dataset_params)\n",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, train_loader, dataset_params, model_params, traing_params)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      9\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m it, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     12\u001b[0m         inputs, labels, lengths, mask, label_idx, extra \u001b[38;5;241m=\u001b[39m unpack_batch_for_lyon(batch)\n\u001b[1;32m     14\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniforge3/envs/rl-book/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniforge3/envs/rl-book/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniforge3/envs/rl-book/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/miniforge3/envs/rl-book/lib/python3.9/site-packages/torch/utils/data/dataset.py:419\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/miniforge3/envs/rl-book/lib/python3.9/site-packages/torch/utils/data/dataset.py:419\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[3], line 90\u001b[0m, in \u001b[0;36mLyonDecimation128Dataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m---> 90\u001b[0m     path, speaker, utterance, digit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     91\u001b[0m     mat \u001b[38;5;241m=\u001b[39m loadmat(path)\n\u001b[1;32m     92\u001b[0m     spec \u001b[38;5;241m=\u001b[39m mat[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspec\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# expected shape (77, T)\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_list = [1,2,3,4,5]\n",
    "\n",
    "#各種のパラメータ設定\n",
    "dataset_params = {\"seq_start\" : 400, \"seq_end\" : 1200, \"sequence_length\": 800, \"slicing_size\" : 1, \"augmentation_factor\": 0, \"batch_size\" : 32, \"Onehot_Encoding\" : None, \"augmentation_mu\" : 0, \"augmentation_sigma\" : 0, \"augmentation_shift\" : 1}\n",
    "model_params = {\"reservoir_size\" : [100],\"input_size\" : [77], \"channel_size\" : [1],  \"reservoir_weights_scale\" : [1], \"input_weights_scale\" : [1], \"spectral_radius\" : [0.9],\"reservoir_density\" : [0.05], \"leak_rate\" : [1], \"Batch_Training\" : [True], \"ReadOut_output_size\" : [10], \"Regularization_L2\" : [0.01]}\n",
    "training_params = {\"num_epochs\" : 1, \"learning_rate\" : 0.01, \"weight_decay\" : 1e-2, \"testdata_ratio\" : 0, \"n_splits\" : 5}\n",
    "\n",
    "#それぞれのモデルパラメータ候補を辞書に格納する\n",
    "model_params = model_params_candinate(model_params)\n",
    "\n",
    "#学習データセットの設定\n",
    "data_dir=\"./Lyon_decimation_128/\"\n",
    "cross_val_loaders, test_loader = prepare_datasets(dataset_params, training_params, data_dir, train_list)\n",
    "\n",
    "# wandb.init(project=\"uskin_test_ESN\", config=config_dictionary)\n",
    "\n",
    "#モデルパラメータの候補ごとに，総当たりしてパラメータを探索する\n",
    "\n",
    "for each_model_params in model_params:\n",
    "    \n",
    "#     model = LSTMModel(each_model_params).to(device)\n",
    "    model = ESN(each_model_params, training_params, dataset_params).to(device)\n",
    "    model_sturcture = model_sturcture_dict(model)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = float(training_params[\"learning_rate\"]), weight_decay = float(training_params[\"weight_decay\"]))\n",
    "    \n",
    "    config_dictionary = {\n",
    "    \"dataset\": data_dir,\n",
    "    \"dataset_params\" : dataset_params,\n",
    "    \"architecture\": model.__class__.__name__,\n",
    "    \"model_params\" : each_model_params,\n",
    "    \"model_sturcture\" : model_sturcture,\n",
    "    \"traing_params\" : training_params,\n",
    "    \"criterion\" : str(criterion),\n",
    "    \"optimizer\" : str(optimizer),\n",
    "    }\n",
    "\n",
    "    wandb.init(project=\"Lyon_test_ESN\", config=config_dictionary)\n",
    "\n",
    "    # 4. k-fold交差検証のループ\n",
    "    for fold, (train_loader, val_loader) in enumerate(cross_val_loaders):\n",
    "        print(f'FOLD {fold}')\n",
    "        print('--------------------------------')\n",
    "\n",
    "        train_model(model, criterion, optimizer, train_loader, dataset_params, each_model_params, training_params)\n",
    "        validate_model(model, val_loader,dataset_params, each_model_params)\n",
    "        model.__init__(each_model_params, training_params, dataset_params)\n",
    "\n",
    "    print('CrossVaridation Finished')\n",
    "    print('--------------------------------')\n",
    "    #テストデータによる評価\n",
    "    # テストデータローダーの準備\n",
    "\n",
    "#     test_model(model, test_loader)\n",
    "    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2dcf2e-2b2c-4e35-942d-6aa28bacaf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model: nn.Module):\n",
    "    print(\"\\n===== Model Parameters =====\")\n",
    "    for name, param in model.named_parameters():\n",
    "        print(\n",
    "            f\"{name:40s} | shape={tuple(param.shape)} | requires_grad={param.requires_grad}\"\n",
    "        )\n",
    "\n",
    "def print_esn_layer_details(model: ESN):\n",
    "    print(\"\\n===== ESN Layer Details =====\")\n",
    "\n",
    "    # --- Echo State Network ---\n",
    "    esn = model.ESN\n",
    "    print(\"\\n--- EchoStateNetwork ---\")\n",
    "    print(f\"reservoir_size        : {esn.reservoir_size}\")\n",
    "    print(f\"input_size            : {esn.input_size}\")\n",
    "    print(f\"channel_size          : {esn.channel_size}\")\n",
    "    print(f\"sequence_length       : {esn.sequence_length}\")\n",
    "    print(f\"leak_rate             : {esn.leak_rate}\")\n",
    "    print(f\"spectral_radius       : {esn.spectral_radius}\")\n",
    "    print(f\"reservoir_density     : {esn.density}\")\n",
    "    print(f\"input_weights_scale   : {esn.input_weights_scale}\")\n",
    "    print(f\"reservoir_weights_scale: {esn.reservoir_weights_scale}\")\n",
    "\n",
    "    print(\"\\n[Reservoir Weights]\")\n",
    "    print(f\"shape         : {tuple(esn.reservoir_weights.shape)}\")\n",
    "    print(f\"requires_grad : {esn.reservoir_weights.requires_grad}\")\n",
    "\n",
    "    print(\"\\n[Input Weights]\")\n",
    "    print(f\"shape         : {tuple(esn.input_weights.shape)}\")\n",
    "    print(f\"requires_grad : {esn.input_weights.requires_grad}\")\n",
    "\n",
    "    print(\"\\n[Last Reservoir State]\")\n",
    "    print(f\"shape         : {tuple(esn.last_reservoir_state_matrix.shape)}\")\n",
    "\n",
    "    # --- ReadOut ---\n",
    "    readout = model.ReadOut\n",
    "    print(\"\\n--- ReadOut ---\")\n",
    "    print(f\"reservoir_state_matrix_size : {readout.reservoir_state_matrix_size}\")\n",
    "    print(f\"output_size                 : {readout.output_size}\")\n",
    "    print(f\"channel_size                : {readout.channel_size}\")\n",
    "    print(f\"sequence_length             : {readout.sequence_length}\")\n",
    "    print(f\"batch_training              : {readout.batch_training}\")\n",
    "\n",
    "    print(\"\\n[ReadOut Dense Layer]\")\n",
    "    print(f\"weight shape    : {tuple(readout.readout_dense.weight.shape)}\")\n",
    "    print(f\"requires_grad   : {readout.readout_dense.weight.requires_grad}\")\n",
    "    print(f\"bias            : {readout.readout_dense.bias}\")\n",
    "\n",
    "def print_model_structure(model: nn.Module):\n",
    "    print(\"===== Model Structure (Hierarchy) =====\")\n",
    "    for name, module in model.named_modules():\n",
    "        if name == \"\":\n",
    "            continue\n",
    "        print(f\"[{name}] -> {module.__class__.__name__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72266ce6-7201-453e-b4e8-e81ae934663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ESN(each_model_params, training_params, dataset_params).to(device)\n",
    "print_model_structure(model)\n",
    "print_esn_layer_details(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab12a5-a241-4a2c-9798-d8d8491d3532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
